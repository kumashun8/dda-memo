# 3章 ストレージと抽出

- [3章 ストレージと抽出](#3章-ストレージと抽出)
  - [3.1 データベースを駆動するデータ構造](#31-データベースを駆動するデータ構造)
    - [3.1.1 ハッシュインデックス](#311-ハッシュインデックス)
    - [3.1.2 SSTableとLSMツリー](#312-sstableとlsmツリー)
    - [3.1.3　Bツリー](#313bツリー)
    - [3.1.4 BツリーとLSMツリーの比較](#314-bツリーとlsmツリーの比較)
    - [3.1.5 その他のインデックス構造](#315-その他のインデックス構造)
  - [3.2 トランザクション処理か分析処理か？](#32-トランザクション処理か分析処理か)
    - [3.2.1 データウェアハウス](#321-データウェアハウス)
    - [3.2.2 スターとスノーフレーク](#322-スターとスノーフレーク)
  - [3.3 列指向ストレージ](#33-列指向ストレージ)
    - [3.3.1 列の圧縮](#331-列の圧縮)
    - [3.3.2 列ストレージにおけるソート順序](#332-列ストレージにおけるソート順序)
    - [3.3.3 列指向ストレージへの書き込み](#333-列指向ストレージへの書き込み)
  - [まとめ](#まとめ)

## 3.1 データベースを駆動するデータ構造

setが追加だけならBashのget/set関数でデータベースは作れる
がgetがO(n)になる
そのためのインデックス
クエスのパフォーマンスにのみ影響
時にクエリを低速にするので追加には注意する

### 3.1.1 ハッシュインデックス

キーに対するデータファイル中のバイトオフセットをマッピングする
ストレージエンジン: Bitcask
全てのキーがRAMに収まっている必要がある
大量の書き込みは発生するがキーの数がそれほど多くない時に○

ディスクを使い切りそうになったらどうするか(追記しかないので)
ログが一定サイズになったらファイルをクローズして
新しいセグメントに書き込みを始める
各セグメント中で重複するキーを捨てるコンパクション処理をする
コンパクションされて小さくなったセグメントはマージもできる
常に新しいセグメントからキーを探すようにする

問題

- 再起動
  - メモリ上のハッシュマップは無くなるので再起動時にセグメント(ファイル)から再構築できる
  - が時間がかかるのでハッシュマップのスナップショットを撮っておくと良い
- 部分的に書き込まれたデータ
  - ログのレコードにチェックサムを含めて、壊れているログか判断できるようにする
- 読み取りの並行処理は可能

追記だけの設計が、更新し続けるのより優れている点

- セグメントへの追記とマージはシーケンシャルで、ランダムな書き込みより高速
- 追記だとイミュータブルなので途中でクラッシュしてもリカバリが容易
- マージによってフラグメンテーションを防ぐ

制約

- メモリサイズ的に上限がある
- キーの範囲指定スキャンはハッシュマップ全体のルックアップが必要

### 3.1.2 SSTableとLSMツリー

- セグメントファイルにキーでソートされている
- それぞれのキーは一度しか現れない
という条件を加える
= Sorted String Table(SSTable) ソート済み文字列テーブル

- マージを効率的に行える
- 全てのキーをメモリに保持する必要がなくなる
  - Handiworkというキーを探している時、それがメモリになくても
  - Handbagとhandsomeというキーのオフセットがわかればその間をスキャンすればいいとわかる

どうソートするか

- 書き込み要求が来たらメモリ上のmemtable(バランスドツリーデータ)に追加する
- Memtableが閾値を超えたらSSTableのファイルとしてディスクに書き出す　ソートされているから効率的に書き出せる
- 読み取りはそのキーをmemtableで探す　なければ新しい順にセグメントを読む
- バックグラウンドでマージなどを行う

問題が一つだけ残る => ディスクに書き込まれないままmemtableの内容がロストすること
対策としてディスク上に別個のログを持っておく
SSTableに書き込まれるたびに対応するログは消せる

上記の仕組みを使ったインデックス構造はLSM(Log-Structured Merge)ツリーと呼ばれる
採用しているストレージエンジンはLSMストレージエンジン
Cassandra、HBase

ElasticsearchやSolrで使われている全文検索のためのインデックスエンジンLuceneも同じ手法でterm dictionaryを保存している

LSMツリーの課題
キーが存在しないことを確認するためには全てのmemtable+ディスクを調べる必要がある
ので追加でブルームフィルターを使う...集合の内容を保持するメモリ効率のいいデータ構造

コンパクションとマージのタイミング

- サイズごと
  - 小さいセグメントを大きい古いセグメントにマージする
- 階層ごと
  - キーの範囲で古いセグメントを分割
コンパクションをインクリメンタルに行える　繰り返し実行できる

### 3.1.3　Bツリー

RDBの標準的なインデックスとして採用
SSTableと同じなのはkey valueペアをソートされた状態で持つことだけ

固定サイズのブロック,ページに分割 (vs 可変のセグメント)

ページには複数のキーと子のページの参照を含む
-> リーフページに辿り着く　欲しい値そのものか値の場所の参照
子ページの参照数は分岐係数(branching factor) 通常数百程度

キーを追加する場合にページにキーを入れる空き容量がない場合は
ページを二つに分解して、親のページをそれに合わせて変更する
これはツリーのバランスが保たれる(baranced)
n個のツリーを持つBツリーの深さは常にO(log n)になる
ページサイズが4KBで深さが4レベル、分岐係数が500なら最大で256TB保存できる
500^4 * 4 KB =  250000000000 KB => 250 TB

信頼性

データを更新してもツリーの最下層は参照なので変更されない
Vs ログ型の構造と対照的(都度更新する)

ページの上書きはハードウェアの操作になりクラッシュする可能性がある
耐性を持たせる方法として追加のwrite-ahead、WAL、redoログを持たせる

追記のみ行われ、Bツリーへの全ての変更内容をツリーそのものに反映される前に書き込む
WALはデータベースのクラッシュ後にツリーを復元するために使われる
複数スレッドからのアクセス制御にはラッチ 軽量ロックで保護する

最適化

- WALの代わりにコピーオンライトのスキームを使う
  - 変更されたページは別の場所に書いて親ページの新しいバージョンでそっちを参照する
- 短縮したキーを保存してぺージのサイズを小さくする
  - 範囲の境界として十分な情報だけ持たせる
  - キーをたくさん置ける => 分岐係数を増やせる
- リーフページがディスク上でシーケンシャルに並ぶようにする
  - ツリーが大きくなるにつれて処理が複雑になる
  - LSMツリーはマージの際に大きなセグメントに書き換えるのでシーケンシャルな配置が簡単
- リーフページに左右の兄弟ページへの参照を持たせる
  - キーを順番にスキャンする際に親ページに戻る必要がなくなる

### 3.1.4 BツリーとLSMツリーの比較

Bツリーは書き込みを、LSMツリーは読み込みを高速に処理する
LSMはコンパクテーションの際に読み取りが遅くなる

項目|LSM|Bツリー|備考
------|---|---|---
インデックスの書き込み回数|任意回数|最低二回|書き込みに差があることを書き込みの輻輳という
書き込みのスループット|シーケンシャルなので高い||
ディスク使用量|少ない|未使用のままのディスク領域が生じるので多い|
読み書きへの影響|コンパクションによるディスク待ち、DBへの書き込みペースにコンパクションが追いつかなくなる、セグメントが増えて走査に時間がかかる||
キーの位置|複数セグメント間に存在しうる|インデックス中に1つしかないので強いトランザクションに向いてる||
||||

### 3.1.5 その他のインデックス構造

DBのプライマリキーのインデックスは上記のkey valueペアのインデックス
キーがユニークでないセカンダリインデックスを自由に追加できる

クエリの結果で得られるのは実際の行か保存されている行への参照
その場所はヒープファイルと呼ばれる
複数のセカンダリインデックスがある場合にデータが複製されるのを防ぐため
ヒープファイルの更新には、新しいデータへのポインタをそこに残すことも可能
    ホップが増える
    インデックス付けされた行を直接インデックス内に保存したほうがいい => クラスタ化インデックス

MySQLのストレージエンジンであるInnoDBはクラスタ化インデックスを使っている
セカンダリーインデックスはプライマリキーへの参照を持つ

インデックスだけでクエリを返せる = インデックスがクエリをカバーしている
クラスタ化インデックスはクエリをカバーできる
一部の列だけインデックス内に保存するタイプをカバーリングインデックスという

複合インデックス

姓、名から電話番号をへのインデックスとなるようやつ
特定の姓を持つ人を検索するクエリはインデックスを使えるが、名を指定すると使えない

お店の位置情報を扱うデータベースの場合緯度と経度の組み合わせで調べる必要があり
標準的なBツリーやLSMツリーでは効率的に探せない
R木というデータ構造を使う空間インデックスを使うことができる

全文検索と曖昧インデックス

Lucenceでは曖昧検索のためにはキーを探すだけではなく、キーの近くにあるキーも探す必要がある
そのオフセットをクエリに教えるためのインデックスが必要になる
trie似たキーの文字に対する有限状態オートマンを使う
与えられた編集距離内にある語の効率的な検索をサポートするれーべンシュタインオートマンに変換できる

全データのメモリの保持

データベースのサイズがメモリに収まる場合はデータベースのデータをメモリに保持できるようになった
耐久性を持ったインメモリデータベースが生まれる
再起動してもデータが失われないような作り(ディスクやネットワークからの復元が必要)

リレーショナルデータベースを持つインメモリデータベース
VoltDB、MemSQL、Oracle TimesTen

RAMCloudは分散データベースで、データをメモリに保持するので永続性がある

インメモリデータベースのパフォーマンスのメリットはディスクから読みらなくてもいいことではない
ディスクからの読み取りはOSのキャッシュによって高速化される場合もあるから
真のメリットはディスクベースのインデックスでは実装が難しいデータモデルを提供できる
e.g. Redisのプライオリティキュー、集合

アンキャッシングアプローチ
インメモリデータべースのアーキテクチャを拡張して大きなデータセットをサポートする

NVM(Non-Volatile Memory)、不揮発性メモリが広く使われればストレージの設計は大

## 3.2 トランザクション処理か分析処理か？

単にクライアントが低レイテンシで読み書きすることをトランザクションと呼ぶ
Vs batch

レコードの挿入削除はユーザーの入力に基づいてインタラクティブに行われる
OLTP(OnLine Transaction Processing)と呼ばれる

データベースはデータ分析のために利用されることもある
OLAP(OnLine Analytical Processing)と呼ばれる
ビジネスインテリジェンス(BI)を向上させる
例: ある期間の売り上げを集計する、どの製品が売れているかを調べる

1990年代からOLAPのためにデータウェアハウスが使われるようになった

### 3.2.1 データウェアハウス

OLTPの処理に影響を与えることなく分析できる
企業内様々なOLTPシステムのコピーをreadonlyでデータウェアハウスに集める
分析できる形式に変換するのをETL(Extract, Transform, Load)と呼ぶ

OLTPデータベースとデータウェアハウスの違い

最適化されているSQLクエリのインターフェースが異なる

Microsoft SQL ServerやSAP HANAなどのデータベースはOLTPとOLAPの両方をサポートしている
しかし、徐々に独立したストレージになった

Teradata、Verticana、SAP HANA、ParAccelといったベンダーは商用のデータウェアハウスを提供している

Amazon RedshiftはParAccelをベースにしている

SQL-on-Hadoopはオープンソースのデータウェアハウスの実装である
Hive、Impala、Presto、Spark SQL、Drillなどがある

### 3.2.2 スターとスノーフレーク

分析の分野においてデータモデルにそれほど多様性はない
よく使われるのはスタースキーマ(ディメンションモデル)

スタースキーマはスターの中心にファクトテーブルがあり、その周りにディメンションテーブルがある
特定の時点で生じたイベントが行になっている
Apple、eBayとかだと数十ペタバイトのデータがある

スターと呼ばれるのは、ディメンションテーブルがファクトテーブルに向かって放射状に伸びているから

このパターンのバリエーションにスノーフレークスキーマがある
ディメンションがさらにサブディメンションに分割されている
スタースキーマよりも正規化されているが、シンプルなぶんスタースキーマが好まれることがある

## 3.3 列指向ストレージ

ファクトテーブルの列は100以上になるが典型的にアクセスするのは4,5列程度

多くのOLTPデータベースは行指向でレイアウトされている
1行の中にある値は隣り合うように配置される

列指向ストレージでは列ごとにデータを格納する
それぞれの列のファイルが同じ順序で行を保持する必要がある

### 3.3.1 列の圧縮

列指向ストレージでは圧縮が容易
同じ値が繰り返されることが多いので、圧縮率が高い
ビットマップエンコーディング
列の値をビットマップに割り当ててその行が持つ値を1にする
ビット列が増えたらランレングス圧縮を行う

WHERE条件でビットマップのANDやORが使える

- 列指向だと密な(関数呼び出しをしない)ループ内で処理ができるのでCPUサイクルを節約できる
- ビット単位の演算は圧縮された列のデータチャンクにも使える ベクトル化処理

### 3.3.2 列ストレージにおけるソート順序

データのソートは行全体を並べ替える必要がある
よく使われるキーをソートキーにする

ソート列が持つユニークな値の数が少ない場合、ソート列の値をビットマップに割り当てることで圧縮できる

- ビットマップはソート列の値の数だけ必要になる
- ビットマップの圧縮率は高いので、ソート列の圧縮率も高くなる

Vertica
冗長に持ったデータを異なるソート順序でソートしておけば、処理したいクエリに適したバージョンを使える
列指向ではポインタは使わない 列だけが値を持っている

### 3.3.3 列指向ストレージへの書き込み

実体化された集計(materialized aggregate)を使う

- 集計を行うクエリを実行すると、結果をファイルに書き込む=materialsized view
- そのファイルをクエリの結果として返す
- 集計を行うクエリは、実体化された集計のファイルを参照する
- 実体化された集計は、定期的に更新される
  - データウェアハウスでは読み取りの負荷が高いので気にならない

特化したケースで使われるのはデータキューブ、OLAPキューブ(様々なディメンションごとにグループ化された集計値のグリッド)

## まとめ

- ストレージエンジンは大まかにトランザクション処理と分析処理に分けられる(OLTPとOLAP)
- OLTPはユーザーの入力に基づいてデータを更新する。低レイテンシが求められ、ディスクのシークがボトルネックになる
  - log-structuredストレージエンジンは書き込みを追記だけにすることで、書き込みをシーケンシャルにし、ディスクのシークを減らす
- OLAPはデータを読み込んで集計する。データセットが大きく、ディスクの帯域幅がボトルネックになる
  - 列指向ストレージエンジンはデータを圧縮して、ディスクの帯域幅を節約する
