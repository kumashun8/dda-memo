# 4章 エンコーディングと進化

- [4章 エンコーディングと進化](#4章-エンコーディングと進化)
  - [4.1 データエンコードのフォーマット](#41-データエンコードのフォーマット)
    - [4.1.1 言語固有のフォーマット](#411-言語固有のフォーマット)
    - [4.1.2 JSON, XML, 様々なバイナリフォーマット](#412-json-xml-様々なバイナリフォーマット)
      - [4.1.2.1 バイナリエンコーディング](#4121-バイナリエンコーディング)
    - [4.1.3 ThriftとProtocol Buffers](#413-thriftとprotocol-buffers)
      - [4.1.3.1 フィールドタグとスキーマの進化](#4131-フィールドタグとスキーマの進化)
      - [4.1.3.2 データ型とスキーマの進化](#4132-データ型とスキーマの進化)
    - [4.1.4 Avro](#414-avro)
      - [4.1.4.1 ライターのスキーマとリーダーのスキーマ](#4141-ライターのスキーマとリーダーのスキーマ)
      - [4.1.4.2 スキーマの進化の規則](#4142-スキーマの進化の規則)
      - [4.1.4.3 そもそもライターのスキーマとは何なのか?](#4143-そもそもライターのスキーマとは何なのか)
      - [4.1.4.4 動的に生成されたスキーマ](#4144-動的に生成されたスキーマ)
  - [4.2 データフローの形態](#42-データフローの形態)

時間と共にアプリケーションが進化するのと同じくして、データフォーマットも新しくなる。
新旧フォーマットのデータが共存するなか、アプリケーションのコードはどう扱うべきか。

- 後方互換性: 古いコードで新しいデータを読み込める
- 前方互換性: 新しいコードで古いデータを読み込める(より難しい)

## 4.1 データエンコードのフォーマット

プログラムはデータを2つの表現で扱う

- インメモリの表現: 構造体やツリー、CPUによるアクセスに最適化されている
- バイト列: ファイルに書き込んだりネットワークを通じて送信するときの表現

インメモリからバイト列に変換することをエンコード、その逆をデコードと呼ぶ。
(シリアライズとデシリアライズ、マーシャルとアンマーシャルとも呼ばれる)

### 4.1.1 言語固有のフォーマット

各プログラミング言語にエンコーディングライブラリがあるがいくつか問題を抱える
例: JavaのSerializable、Pythonのpickle、RubyのMarshal

- 別の言語でデコードできない、読むのが難しいことがある
- デコーディング側は任意のクラスをインスタンス化できる必要があり、セキュリティ上の問題がある
- 利用の手軽さが優先され、後方または前方互換性がないことがある
　　- パフォーマンスもまた重要視されないこともある(Java)

### 4.1.2 JSON, XML, 様々なバイナリフォーマット

JSONやXMLは標準的なフォーマットで、多くの言語でサポートされている。
webブラウで最初からサポートされていたりシンプルだったりでJSONが人気。が、いくつか問題もある。

- CSV含め人間が読めるフォーマットはデバッグに便利だが数値のエンコーディングは曖昧。
　- XML、CSVは数値と文字を区別できず、JSONは整数値と少数を区別できない
- JSONとXMLはバイナリ文字列(文字列エンコーディングされてないバイトの並び)をサポートしていない
  - バイナリデータをBase64でエンコードする必要がある
  - それを示すスキーマも必要なのでデータサイズが大きくなる
- JSONとXMLではそれぞれのスキーマ言語があるが、そのために適切なエンコード・デコード処理を書く必要がある
-　CSVにはスキーマ言語がないので、データを扱パーサーが全て正しく解釈できるとは限らない

上記の欠陥を無視できるほどに多くの目的を十分に満たすので、実際にはあまり問題にならない。

#### 4.1.2.1 バイナリエンコーディング

JSONのバイナリエンコーディングにはMessagePackやBSON、BJSONなどが
XMLのバイナリエンコーディングにはFast Infoset、WBXMLが
あるがテキスト形式のエンコーディングの方がよく使われる。

MessagePackを使ってJSONをエンコーディングした結果のバイト列

1. 先頭バイトはデータの型を示す。0x83ならオブジェクト型で、フィールドが3つあることを示す
2. 2番目のバイトは次に続くデータ型とその長さを示す。0xa8なら文字列型で、長さは8バイト
3. 3番目のバイトから8バイトは文字列のデータ本体(最初のフィールド"userName"の名前)
4. 続くバイトはフィールドの値がその長さをプレフィックスに格納されている

この方法では元々のJSONのデータサイズとそこまで変わらない。

### 4.1.3 ThriftとProtocol Buffers

Thrift(Facebook)とProtocol Buffers(Google)は、データのスキーマを定義するためのIDL(Interface Definition Language)を持ったバイナリエンコーディングライブラリ。

ThriftのIDL

```thrift
struct Person {
  1: required string userName,
  2: optional i32 favoriteNumber,
  3: optional list<string> interests
}
```

protocol buffersのIDL

```protobuf
message Person {
  required string userName　　　　= 1;
  optional int32  favoriteNumber = 2;
  repeated string interests      = 3;
}
```

IDLからコードを生成することで、各プログラミング言語でデータのエンコード・デコードを行うクラスを作成できる。

ThriftではBinaryProtocol、CompactProtocolという異なるエンコーディングフォーマットがある。

BinaryProtocol

エンコードの方式はMessagePackと似ているが、

- フィールド名の代わりにフィールドタグが格納される
- 値の長さは必要に応じて格納される(favoirteNumberは不要)

CompactProtocol

- フィールドの型とフィールドタグが1バイトにまとめられる
- 可変調整数を使うことで数値の長さを格納するのに必要なバイト数を減らす
  - 各バイトの先頭ビットが1なら次のバイトを使ってそれ以降もバイトが続くことを示す
  - -64から63までの数値は1バイトで表現できる

Protocol BuffersはThriftのCompactProtocolと似ている。

スキーマで示されるrequired, optional, repeatedは、エンコードされたデータには含まれない。
enableを指定されると実行時にチェックされ、データが欠けている場合はエンコーディングに失敗するようになっている。

#### 4.1.3.1 フィールドタグとスキーマの進化

ThriftやProtocl Buffersではどうやってスキーマの後方および前方互換性を実現しているのか。

前方互換性(新しいスキーマで古いデータを読み込める)

新しいタグ番号を使えば新しいフィールドを追加できる。
仮に古いコードが新しいコードで書かれたデータを読み込んだとしても、新しいフィールドは無視される。
パーサーがデータ型のアノテーションを見れば無視するバイト数を判別できる。

後方互換性(古いスキーマで新しいデータを読み込める)

最初にデプロイした後に追加する全てのフィールドには、optionalを指定する。もしくは初期値を指定する必要がある。

なお、フィールドの削除は扱いが逆になる

- 削除できるのはoptionalなフィールドだけ
- 同じタグを使いまわせない

#### 4.1.3.2 データ型とスキーマの進化

データ型の変更はどうやって扱うのか。
32bit整数から64bit整数に変更する場合、データ型の変更は後方互換性を壊す。

Protocol Buffersにはrepeatedが指定されると同じフィールドタグが複数回レコードに現れる。
optional(0か1か)なフィールドを後からrepeated(複数ある)に変更することはできる。

### 4.1.4 Avro

Apache Avroもまたバイナリエンコーディングフォーマットで、Thriftの代わりにHadoopの副プロジェクトとして生まれた。
人間が編集するための(Avro IDL)と、機械が読み取りやすいJSONベースの2つのスキーマ言語がある。

Avro IDL

```avro
record Person {
    string userName;
    union { null, long } favoriteNumber = null;
    array<string> interests;
}
```

対応するJSON

```json
{
    ”type”: ”record”,
    ”name”: ”Person”,
    ”fields”: [
    　  { ”name”: ”userName”, ”type”: ”string” },
    　  { ”name”: ”favoriteNumber”, ”type”: [ ”null”, ”long” ], ”default”: null },
    　  { ”name”: ”interests”, ”type”: { ”type”: ”array”, ”items”: ”string” } }
    ]　   
}
```

Protocol Buffersにあるようなタグ番号がないので、エンコーディング後のサイズは最もコンパクトになる。
値だけが連結される。
そのためデコードする側は書き込まれた時と完全に同じスキーマを使う必要がある。

#### 4.1.4.1 ライターのスキーマとリーダーのスキーマ

ライターのスキーマ...データをエンコードするときに使うスキーマ
リーダーのスキーマ...データをデコードするときに使うスキーマ

Avroではライターのスキーマとリーダーのスキーマが同一である必要はなく、互換性さえあればいい。
データが読み込まれる際にAvroライブラリはこの差異を解決し、ライターのスキーマからリーダーのスキーマに変換する。

リーダーのスキーマが期待するフィールドをライターのスキーマが持っていない場合、デフォルト値が使われる。

#### 4.1.4.2 スキーマの進化の規則

Avroにおける前方互換性...新しいバージョンのスキーマをライターが持ち、古いバージョンのスキーマをリーダーとして持てること

Avroにおける後方互換性...古いバージョンのスキーマをライターが持ち、新しいバージョンのスキーマをリーダーとして持てること

そのため追加および削除できるのはデフォルト値を持つフィールドのみ。

Avroでnullを扱う場合union型を使う。nullを含む型のリストを指定する。

```avro
union { null, long }　favoriteNumber = null;
```

よってrequired, optionalのような概念はない。

フィールドのデータ型の変更は可能
リーダーのスキーマはフィールド名にエイリアスを持たせられるので、古いライターのスキーマのフィールド名にあるデータを新しいスキーマのフィールド名で読み込める。よって後方互換性は保たれるが、前方互換性は保たれない。

#### 4.1.4.3 そもそもライターのスキーマとは何なのか?

データがエンコードされた際のライターのスキーマを、リーダーはどのようにして知るのか

- 大量のレコードを持つ大きなファイルの場合
  - ファイルのライターが先頭に一度だけスキーマを書き込む
- 個別にレコードが書かれるデータベースの場合
  - 異なるライターのスキーマを使って様々なレコードが書き込まれる
  - エンコードされた全てのレコードの先頭にいバージョン番号を振る
    - 番号に対応するスキーマをDB内に保存しておく(インクリメンタル、ハッシュ値)
- ネットワーク経由でレコードを送信する場合
  - プロセスが双方向のネットワーク接続で通信する場合
  - コネクション確立時にスキーマのバージョンに関するネゴシエーションを行う

#### 4.1.4.4 動的に生成されたスキーマ

ThriftとProtocol BuffersはIDLからコードを生成する。静的型付言語であれば実装時に型チェックやIDEによる自動補完機能が利用できる。

動的型付言語では型チェックがないので同じようなメリットはないが、コード生成しなければ明示的なコンパイルのステップを避けられる。？

コード生成しなくても、ライターのスキーマが埋め込まれたオブジェクトコンテナファイルをAvroライブラリで識別することでスキーマを読み込める。このファイルは自己記述型である。(必要なファイルのメタデータが全て揃っている)

例: Apache Pig

DBのテーブルなどから動的に生成されたスキーマの場合はコード生成が邪魔になる。

## 4.2 データフローの形態
